# -*- coding: utf-8 -*-
"""Submission_deploy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Lw2twnYem9s23C5mQz0WyoOf8nCg6HVd
"""

import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
import matplotlib.pyplot as plt

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

!kaggle datasets download -d zarkonium/synthetic-image-dataset-cats-dogs-bikes-cars

!mkdir dataset
!unzip -qq synthetic-image-dataset-cats-dogs-bikes-cars.zip -d dataset
!ls dataset

import os

dataset = os.path.basename('dataset')

from tensorflow.keras.preprocessing.image import ImageDataGenerator
 
train_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=20,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    fill_mode = 'nearest',
                    validation_split=0.2
                    )
 
test_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=20,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    fill_mode = 'nearest',
                    validation_split=0.2)

train_generator = train_datagen.flow_from_directory(
        dataset, 
        target_size=(150, 150),  # mengubah resolusi seluruh gambar menjadi 150x150 piksel
        subset='training',
        batch_size = 48,
        shuffle = True,
        class_mode='categorical')
 
validation_generator = test_datagen.flow_from_directory(
        dataset, 
        target_size=(150, 150), # mengubah resolusi seluruh gambar menjadi 150x150 piksel
        subset='validation',
        batch_size =48,
        shuffle = True,
        class_mode='categorical')

model = tf.keras.models.Sequential([                                              
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)), 
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),                        
    tf.keras.layers.MaxPooling2D(2,2), 
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),                         
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),                                                    
    tf.keras.layers.Dropout(0.5), # menggunakan Dropout Regularization
    tf.keras.layers.Dense(128, activation='relu'),                                
    tf.keras.layers.Dense(512, activation='relu'),                                
    tf.keras.layers.Dense(4, activation='softmax')                        
])

model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

from keras.callbacks import LearningRateScheduler
# menghentikan fit model ketika akurasi = 97

class callback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > 0.92 and logs.get('val_accuracy')>0.92):
      print("Fit Berhenti Karena Akurasi Melebihi 92%")
      self.model.stop_training = True

callbacks = callback()

model_fit = model.fit(
      train_generator,
      steps_per_epoch=25,
      epochs=50,
      validation_data=validation_generator,
      validation_steps=5,
      verbose=2,
      callbacks=[callbacks],
      )

model_fit

plt.plot(model_fit.history['accuracy'])
plt.plot(model_fit.history['val_accuracy'])
plt.title('Accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(model_fit.history['loss'])
plt.plot(model_fit.history['val_loss'])
plt.title('Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)

!ls -la | grep 'model'